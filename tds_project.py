# -*- coding: utf-8 -*-
"""TDS_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HX_Dok_4Mgb0Z51QkWyUUv7wRFPrjp24

Installing Libraries
"""

import pandas as pd
pd.__version__
import requests

import time
from google.colab import drive

# Mount Google Drive to save the output CSV
drive.mount('/content/drive')

"""GitHub API Token:"""

import requests

token = input("Enter your GitHub token: ")
headers = {"Authorization": f"token {token}"}

"""Company name cleaning function

"""

def clean_company(company):
    if company:
        company = company.strip()               # Remove whitespace
        if company.startswith('@'):
            company = company[1:]               # Remove leading '@'
        company = company.upper()               # Convert to uppercase
    return company

"""Function to fetch user details and repo details"""

# Define function to fetch user details
def fetch_user_data(user_data):
    return {
        "login": user_data.get("login"),
        "name": user_data.get("name"),
        "company": clean_company(user_data.get("company")),
        "location": user_data.get("location"),
        "email": user_data.get("email"),
        "hireable": user_data.get("hireable"),
        "bio": user_data.get("bio"),
        "public_repos": user_data.get("public_repos"),
        "followers": user_data.get("followers"),
        "following": user_data.get("following"),
        "created_at": user_data.get("created_at")
    }

# Define function to fetch repository details
def fetch_repository_data(repos_data, username):
    repo_list = []
    for repo in repos_data:
        repo_info = {
            "login": username,
            "full_name": repo.get("full_name"),
            "created_at": repo.get("created_at"),
            "stargazers_count": repo.get("stargazers_count"),
            "watchers_count": repo.get("watchers_count"),
            "language": repo.get("language"),
            "has_projects": repo.get("has_projects"),
            "has_wiki": repo.get("has_wiki"),
            "license_name": repo.get("license", {}).get("key") if repo.get("license") is not None else None
        }
        repo_list.append(repo_info)
    return repo_list

"""API URL to search for users in Boston with more than 100 followers"""

##Displays max 100 users per page
#Total number of users to fetch: 469
url = "https://api.github.com/search/users?q=location:boston+followers:%3E100&per_page=100"
response = requests.get(url, headers=headers)
data = response.json()

# Lists to store user and repository data
user_details = []
all_repositories = []

page = 1
while True:
    print(f"Fetching page {page}")
    response = requests.get(f"{url}&page={page}", headers=headers)
    users = response.json().get("items", [])

    if not users:  # Exit loop if no more users are found
        break

    for user in users:
        username = user["login"]
        user_url = f"https://api.github.com/users/{username}"
        user_response = requests.get(user_url, headers=headers)
        user_data = user_response.json()

        # Fetch and add user details to user list
        user_details.append(fetch_user_data(user_data))

        # Fetch up to 500 recent repositories for the user
        repo_url = f"https://api.github.com/users/{username}/repos?per_page=100"
        repo_page = 1
        repo_count = 0

        while repo_count < 500:
            repo_response = requests.get(f"{repo_url}&page={repo_page}", headers=headers)
            repos = repo_response.json()
            if not repos:  # Exit loop if no more repositories are found
                break

            # Add repositories to all_repositories list
            all_repositories.extend(fetch_repository_data(repos, username))
            repo_count += len(repos)
            repo_page += 1
            time.sleep(4)  # 4-second delay between each repository page request

        # 4-second delay between each user request
        time.sleep(4)

    page += 1

# Convert to DataFrame and save as CSV
user_df = pd.DataFrame(user_details)
user_df.to_csv("/content/drive/MyDrive/github_users_boston_details.csv", index=False)

repo_df = pd.DataFrame(all_repositories)
repo_df.to_csv("/content/drive/MyDrive/github_repositories_boston.csv", index=False)

print("Data successfully saved to your Google Drive.")